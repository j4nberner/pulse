{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6408df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d8ad0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It learns patterns from data.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"\")\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash-preview-04-17\")  # Use the correct model name\n",
    "response = model.generate_content(\"Explain how AI works in a few words\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed5dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "\n",
    "# --- Configuration ---\n",
    "PROJECT_ID = \"gen-lang-client-0061421706\"  # Replace with your actual project ID\n",
    "LOCATION = \"us-central1\"  # Choose a region where Gemini 1.5 Flash is available (e.g., us-central1)\n",
    "MODEL_NAME = \"gemini-1.5-flash-001\"  # Or \"gemini-1.5-flash\" for the latest stable alias\n",
    "\n",
    "# Initialize Vertex AI\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# Load the model\n",
    "model = GenerativeModel(MODEL_NAME)\n",
    "\n",
    "print(f\"Vertex AI initialized for project: {PROJECT_ID} in location: {LOCATION}\")\n",
    "print(f\"Model loaded: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7627c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation\n",
    "prompt = \"Explain the concept of quantum entanglement in simple terms.\"\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "print(\"\\n--- Text Generation Response ---\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a0e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import base64\n",
    "\n",
    "\n",
    "def generate():\n",
    "    client = genai.Client(\n",
    "        vertexai=True,\n",
    "        project=\"gen-lang-client-0061421706\",\n",
    "        location=\"global\",\n",
    "    )\n",
    "\n",
    "    model = \"gemini-2.5-flash-preview-05-20\"\n",
    "    contents = [types.Content(role=\"user\", parts=[types.Part(text=\"Explain how AI works in a few words\")])]\n",
    "\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "        seed=0,\n",
    "        max_output_tokens=300,\n",
    "        safety_settings=[\n",
    "            types.SafetySetting(category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
    "            types.SafetySetting(\n",
    "                category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"\n",
    "            ),\n",
    "            types.SafetySetting(\n",
    "                category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"\n",
    "            ),\n",
    "            types.SafetySetting(category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=generate_content_config,\n",
    "    ):\n",
    "        print(chunk.text, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a88cdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns from data to find patterns and make predictions or decisions."
     ]
    }
   ],
   "source": [
    "generate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
