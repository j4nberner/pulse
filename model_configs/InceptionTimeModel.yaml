name: "InceptionTimeModel"
pretrained_model_path: null # Path to pretrained model (if any)
params:
  # Basic configuration
  trainer_name: "InceptionTimeTrainer"
  type: "convDL" # Type of model (convML for conventional machine learning, convDL for conventional deep learning and LLM for large language models)
  save_checkpoint_freq: 5
  verbose: 1 # Controls verbosity of output (0 = silent, 1 = log every 10 batches, 2 = log every batch)
  # Training parameters
  num_epochs: 60
  earlystopping_patience: 5
  # Model architecture
  depth: 12
  dropout_rate: 0.3
  # Optimizer settings
  optimizer_name: "adam" # Options: adam, adamw, sgd
  learning_rate: 0.01
  weight_decay: 0.01
  grad_clip_max_norm: 2.0 # max_norm = 1.0 (LSTM, GRU) or 2.0 (CNN, InceptionTime)
  # Scheduler settings
  scheduler_factor: 0.9
  scheduler_patience: 3
  min_lr: 0.001
